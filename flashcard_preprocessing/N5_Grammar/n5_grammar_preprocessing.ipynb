{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned file saved to 'N5_grammar_extracted.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Add JLPT Level, Grammar, Meaning headings and extract these columns only. Filter only N5 rows\n",
    "\n",
    "input_file = \"../jlpt_grammar.csv\" \n",
    "output_file = \"N5_grammar_extracted.csv\"\n",
    "\n",
    "# Define the new headings\n",
    "new_headings = [\"JLPT Level\", \"Grammar\", \"Meaning\"]\n",
    "\n",
    "with open(input_file, \"r\", encoding=\"utf-8-sig\") as infile, open(output_file, \"w\", encoding=\"utf-8-sig\", newline=\"\") as outfile:\n",
    "    reader = csv.reader(infile)\n",
    "    writer = csv.writer(outfile)\n",
    "\n",
    "    # Write the new headings\n",
    "    writer.writerow(new_headings)\n",
    " \n",
    "    for row in reader:\n",
    "        if row[0].strip() == \"N5\":\n",
    "            cleaned_row = [row[0], row[2], row[4]]  # 0: JLPT Level, 2: Grammar, 4: Meaning\n",
    "            writer.writerow(cleaned_row)\n",
    "\n",
    "print(f\"Cleaned file saved to '{output_file}'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No duplicates found across all files.\n"
     ]
    }
   ],
   "source": [
    "# check for duplicate rows\n",
    "\n",
    "all_rows = []\n",
    "duplicates = []\n",
    "seen = set()  # To track unique (Word, Reading) pairs\n",
    "\n",
    "with open(output_file, \"r\", encoding=\"utf-8-sig\") as f:\n",
    "    reader = csv.reader(f)\n",
    "\n",
    "    header = next(reader, None)\n",
    "\n",
    "    for line_num, row in enumerate(reader, start=2):\n",
    "        # Skip empty rows\n",
    "        if not row or all(cell.strip() == \"\" for cell in row):\n",
    "            continue\n",
    "        \n",
    "        # Create a unique key based on Word and Reading (indices 0 and 1)\n",
    "        key = (row[0].strip(), row[1].strip())  # Word and Reading\n",
    "        if key in seen:\n",
    "            duplicates.append((output_file, line_num, row)) \n",
    "        else:\n",
    "            seen.add(key)\n",
    "\n",
    "        all_rows.append(row)\n",
    "\n",
    "if duplicates:\n",
    "    print(\"Duplicates found:\")\n",
    "    for file, line, row in duplicates:\n",
    "        print(f\"File: {file}, Line: {line}, Duplicate Entry: {row}\")\n",
    "else:\n",
    "    print(\"No duplicates found across all files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File with Reading column saved to 'N5_grammar_with_reading.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Add a readings column and add readings to each row\n",
    "\n",
    "input_file = \"N5_grammar_extracted.csv\"\n",
    "output_file = \"N5_grammar_with_reading.csv\"\n",
    "\n",
    "# Grammar and their readings\n",
    "grammar_readings = {\n",
    "    \"ちゃいけない・じゃいけない\": \"ちゃいけない / じゃいけない\",\n",
    "    \"だ・です\": \"だ / です\",\n",
    "    \"だけ\": \"だけ\",\n",
    "    \"だろう\": \"だろう\",\n",
    "    \"で\": \"で\",\n",
    "    \"でも\": \"でも\",\n",
    "    \"でしょう\": \"でしょう\",\n",
    "    \"どんな\": \"どんな\",\n",
    "    \"どうして\": \"どうして\",\n",
    "    \"どうやって\": \"どうやって\",\n",
    "    \"が\": \"が\",\n",
    "    \"があります\": \"があります\",\n",
    "    \"がほしい\": \"がほしい\",\n",
    "    \"がいます\": \"がいます\",\n",
    "    \"ほうがいい\": \"ほうがいい\",\n",
    "    \"い-adjectives\": \"いけいようし\",\n",
    "    \"一番\": \"いちばん\",\n",
    "    \"一緒に\": \"いっしょに\",\n",
    "    \"いつも\": \"いつも\",\n",
    "    \"じゃない・ではない\": \"じゃない / ではない\",\n",
    "    \"か\": \"か\",\n",
    "    \"か〜か\": \"か〜か\",\n",
    "    \"から\": \"から\",\n",
    "    \"方\": \"かた\",\n",
    "    \"けど\": \"けど\",\n",
    "    \"けれども\": \"けれども\",\n",
    "    \"まだ\": \"まだ\",\n",
    "    \"まだ〜ていません\": \"まだ〜ていません\",\n",
    "    \"まで\": \"まで\",\n",
    "    \"前に\": \"まえに\",\n",
    "    \"ませんか\": \"ませんか\",\n",
    "    \"ましょう\": \"ましょう\",\n",
    "    \"ましょうか\": \"ましょうか\",\n",
    "    \"も\": \"も\",\n",
    "    \"もう\": \"もう\",\n",
    "    \"な-adjectives\": \"なけいようし\",\n",
    "    \"なあ\": \"なあ\",\n",
    "    \"ないで\": \"ないで\",\n",
    "    \"ないでください\": \"ないでください\",\n",
    "    \"なくてもいい\": \"なくてもいい\",\n",
    "    \"なくちゃ\": \"なくちゃ\",\n",
    "    \"なくてはいけない\": \"なくてはいけない\",\n",
    "    \"なくてはならない\": \"なくてはならない\",\n",
    "    \"なる\": \"なる\",\n",
    "    \"んです\": \"んです\",\n",
    "    \"ね\": \"ね\",\n",
    "    \"に\": \"に\",\n",
    "    \"にいく\": \"にいく\",\n",
    "    \"にする\": \"にする\",\n",
    "    \"に/へ\": \"に / へ\",\n",
    "    \"の\": \"の\",\n",
    "    \"のです\": \"のです\",\n",
    "    \"のが下手\": \"のがへた\",\n",
    "    \"のが上手\": \"のがじょうず\",\n",
    "    \"のが好き\": \"のがすき\",\n",
    "    \"の中で[A]が一番\": \"のなかで[A]がいちばん\",\n",
    "    \"ので\": \"ので\",\n",
    "    \"を\": \"を\",\n",
    "    \"をください\": \"をください\",\n",
    "    \"しかし\": \"しかし\",\n",
    "    \"すぎる\": \"すぎる\",\n",
    "    \"たことがある\": \"たことがある\",\n",
    "    \"たい\": \"たい\",\n",
    "    \"たり〜たり\": \"たり〜たり\",\n",
    "    \"てある\": \"てある\",\n",
    "    \"ている\": \"ている\",\n",
    "    \"てから\": \"てから\",\n",
    "    \"てください\": \"てください\",\n",
    "    \"てはいけない\": \"てはいけない\",\n",
    "    \"てもいいです\": \"てもいいです\",\n",
    "    \"と\": \"と\",\n",
    "    \"とき\": \"とき\",\n",
    "    \"とても\": \"とても\",\n",
    "    \"つもり\": \"つもり\",\n",
    "    \"は\": \"は\",\n",
    "    \"は〜より・・・です\": \"は〜より・・・です\",\n",
    "    \"はどうですか\": \"はどうですか\",\n",
    "    \"や\": \"や\",\n",
    "    \"よ\": \"よ\",\n",
    "    \"より〜ほうが\": \"より〜ほうが\",\n",
    "}\n",
    "\n",
    "with open(input_file, \"r\", encoding=\"utf-8-sig\") as infile, open(output_file, \"w\", encoding=\"utf-8-sig\", newline=\"\") as outfile:\n",
    "    reader = csv.reader(infile)\n",
    "    writer = csv.writer(outfile)\n",
    "\n",
    "    # Read the header and add the new column\n",
    "    header = next(reader)\n",
    "    header.insert(2, \"Reading\")  # Add Reading column after Grammar\n",
    "    writer.writerow(header)\n",
    "\n",
    "    for row in reader:\n",
    "        grammar = row[1]\n",
    "        reading = grammar_readings.get(grammar, \"No reading available\")\n",
    "        row.insert(2, reading)\n",
    "        writer.writerow(row)\n",
    "\n",
    "print(f\"File with Reading column saved to '{output_file}'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import urllib.parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add example sentences for each word in both Japanese and English\n",
    "\n",
    "def get_word_type_and_sentences(word):\n",
    "    jisho_url = f\"https://jisho.org/api/v1/search/words?keyword={word}\"\n",
    "    \n",
    "    # Always URL-encode the search term to avoid issues with special characters\n",
    "    encoded_word = urllib.parse.quote(word)\n",
    "    tatoeba_url = f\"https://tatoeba.org/en/api_v0/search?query={encoded_word}&from=jpn&to=eng\"\n",
    "\n",
    "    try:\n",
    "        # --- 1) Fetch word type from Jisho ---\n",
    "        response = requests.get(jisho_url)\n",
    "        response.raise_for_status()\n",
    "        jisho_data = response.json()\n",
    "\n",
    "        word_type = \"Unknown\"\n",
    "        if jisho_data.get(\"data\"):\n",
    "            senses = jisho_data[\"data\"][0].get(\"senses\", [])\n",
    "            if senses:\n",
    "                parts = senses[0].get(\"parts_of_speech\", [])\n",
    "                if parts:\n",
    "                    word_type = parts[0]\n",
    "\n",
    "        # --- 2) Fetch example sentences from Tatoeba ---\n",
    "        response = requests.get(tatoeba_url)\n",
    "        response.raise_for_status()\n",
    "        tatoeba_data = response.json()\n",
    "\n",
    "        sentences = []\n",
    "        for sentence in tatoeba_data.get(\"results\", []):\n",
    "            jp_sentence = sentence.get(\"text\", \"\")\n",
    "            \n",
    "            # 'translations' is a list of lists. Flatten them:\n",
    "            translations = sentence.get(\"translations\", [])\n",
    "            all_translations = []\n",
    "            for sublist in translations:\n",
    "                all_translations.extend(sublist)\n",
    "            \n",
    "            # Grab the first English translation if there is one\n",
    "            en_sentence = \"\"\n",
    "            if all_translations:\n",
    "                en_sentence = all_translations[0].get(\"text\", \"\")\n",
    "            \n",
    "            if jp_sentence and en_sentence:\n",
    "                sentences.append((jp_sentence, en_sentence))\n",
    "\n",
    "        return word_type, sentences\n",
    "\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Request failed for {word}: {e}\")\n",
    "        return \"Unknown\", []\n",
    "    except (IndexError, KeyError, AttributeError, TypeError) as e:\n",
    "        print(f\"Unexpected data structure for {word}: {e}\")\n",
    "        return \"Unknown\", []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: ちゃいけない・じゃいけない\n",
      "Processed: だ・です\n",
      "Processed: だけ\n",
      "Processed: だろう\n",
      "Processed: で\n",
      "Processed: でも\n",
      "Processed: でしょう\n",
      "Processed: どんな\n",
      "Processed: どうして\n",
      "Processed: どうやって\n",
      "Processed: が\n",
      "Processed: があります\n",
      "Processed: がほしい\n",
      "Processed: がいます\n",
      "Processed: ほうがいい\n",
      "Processed: い-adjectives\n",
      "Processed: 一番\n",
      "Processed: 一緒に\n",
      "Processed: いつも\n",
      "Processed: じゃない・ではない\n",
      "Processed: か\n",
      "Processed: か〜か\n",
      "Processed: から\n",
      "Processed: 方\n",
      "Processed: けど\n",
      "Processed: けれども\n",
      "Processed: まだ\n",
      "Processed: まだ〜ていません\n",
      "Processed: まで\n",
      "Processed: 前に\n",
      "Processed: ませんか\n",
      "Processed: ましょう\n",
      "Processed: ましょうか\n",
      "Processed: も\n",
      "Processed: もう\n",
      "Processed: な-adjectives\n",
      "Processed: なあ\n",
      "Processed: ないで\n",
      "Processed: ないでください\n",
      "Processed: なくてもいい\n",
      "Processed: なくちゃ\n",
      "Processed: なくてはいけない\n",
      "Processed: なくてはならない\n",
      "Processed: なる\n",
      "Processed: んです\n",
      "Processed: ね\n",
      "Processed: に\n",
      "Processed: にいく\n",
      "Processed: にする\n",
      "Processed: に/へ\n",
      "Processed: の\n",
      "Processed: のです\n",
      "Processed: のが下手\n",
      "Processed: のが上手\n",
      "Processed: のが好き\n",
      "Processed: の中で[A]が一番\n",
      "Processed: ので\n",
      "Processed: を\n",
      "Processed: をください\n",
      "Processed: しかし\n",
      "Processed: すぎる\n",
      "Processed: たことがある\n",
      "Processed: たい\n",
      "Processed: たり〜たり\n",
      "Processed: てある\n",
      "Processed: ている\n",
      "Processed: てから\n",
      "Processed: てください\n",
      "Processed: てはいけない\n",
      "Processed: てもいいです\n",
      "Processed: と\n",
      "Processed: とき\n",
      "Processed: とても\n",
      "Processed: つもり\n",
      "Processed: は\n",
      "Processed: は〜より・・・です\n",
      "Processed: はどうですか\n",
      "Processed: や\n",
      "Processed: よ\n",
      "Processed: より〜ほうが\n",
      "Updated file with word types and example sentences saved to 'N5_grammar_with_examples.csv'.\n"
     ]
    }
   ],
   "source": [
    "# add example sentences for each word in both Japanese and English\n",
    "\n",
    "input_csv = \"N5_grammar_with_reading.csv\"\n",
    "output_csv = \"N5_grammar_with_examples.csv\"\n",
    "\n",
    "with open(input_csv, \"r\", encoding=\"utf-8-sig\") as infile, open(output_csv, \"w\", encoding=\"utf-8-sig\", newline=\"\") as outfile:\n",
    "    reader = csv.DictReader(infile)\n",
    "    fieldnames = reader.fieldnames + [\"Word Type\", \"Example Sentence JP\", \"Example Sentence EN\"]\n",
    "    writer = csv.DictWriter(outfile, fieldnames=fieldnames)\n",
    "\n",
    "    writer.writeheader()\n",
    "\n",
    "    for row in reader:\n",
    "        word = row[\"Grammar\"]\n",
    "        word_type, examples = get_word_type_and_sentences(word)\n",
    "\n",
    "        row[\"Word Type\"] = word_type\n",
    "        if examples:\n",
    "            # Use the first example sentence\n",
    "            row[\"Example Sentence JP\"], row[\"Example Sentence EN\"] = examples[0]\n",
    "        else:\n",
    "            row[\"Example Sentence JP\"] = \"No example available\"\n",
    "            row[\"Example Sentence EN\"] = \"No example available\"\n",
    "\n",
    "        writer.writerow(row)\n",
    "        print(f\"Processed: {word}\")\n",
    "        time.sleep(2)\n",
    "\n",
    "print(f\"Updated file with word types and example sentences saved to '{output_csv}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Updated CSV saved to: N5_grammar_refined_examples.csv\n"
     ]
    }
   ],
   "source": [
    "# replace difficult example sentences with simpler ones\n",
    "\n",
    "replacements = {\n",
    "    \"「もう俺たちの邪魔をしないなら、今までのことは水に流してやってもいいけど？」「やけに寛大なんだな・・・」\": (\n",
    "        \"「もう邪魔しないなら、今までのことは許してあげるよ。」「優しいんだね…」\",\n",
    "        \"\\\"If you won't bother us anymore, I'll let bygones be bygones.\\\" \\\"You're quite kind...\\\"\"\n",
    "    ),\n",
    "    \"馬鹿だろう！\": (\n",
    "        \"馬鹿じゃないの？\",\n",
    "        \"Aren't you an idiot?\"\n",
    "    ),\n",
    "    \"出ろ！\": (\n",
    "        \"出て！\",\n",
    "        \"Get out!\"\n",
    "    ),\n",
    "    \"死ね！\": (\n",
    "        \"やめて！\",\n",
    "        \"Stop it!\"\n",
    "    ),\n",
    "    \"死を忘れるな。\": (\n",
    "        \"死を忘れないで。\",\n",
    "        \"Don't forget about death.\"\n",
    "    ),\n",
    "    \"笑ってはいけない。\": (\n",
    "        \"笑わないでください。\",\n",
    "        \"Don't laugh.\"\n",
    "    ),\n",
    "    \"恥を知れ！\": (\n",
    "        \"恥ずかしいよ！\",\n",
    "        \"That's embarrassing!\"\n",
    "    ),\n",
    "\n",
    "}\n",
    "\n",
    "input_csv = \"N5_grammar_with_examples.csv\" \n",
    "output_csv = \"N5_grammar_refined_examples.csv\" \n",
    "\n",
    "with open(input_csv, \"r\", newline=\"\", encoding=\"utf-8-sig\") as infile, \\\n",
    "     open(output_csv, \"w\", newline=\"\", encoding=\"utf-8-sig\") as outfile:\n",
    "\n",
    "    reader = csv.DictReader(infile)\n",
    "\n",
    "    fieldnames = reader.fieldnames\n",
    "    writer = csv.DictWriter(outfile, fieldnames=fieldnames, extrasaction='ignore')\n",
    "\n",
    "    writer.writeheader()\n",
    "    \n",
    "    for row in reader:\n",
    "        jp = row.get(\"Example Sentence JP\", \"\")\n",
    "        \n",
    "        # If JP sentence is in our dictionary, replace both JP and EN\n",
    "        if jp in replacements:\n",
    "            new_jp, new_en = replacements[jp]\n",
    "            row[\"Example Sentence JP\"] = new_jp\n",
    "            row[\"Example Sentence EN\"] = new_en\n",
    "        \n",
    "        writer.writerow(row)\n",
    "\n",
    "print(\"Done! Updated CSV saved to:\", output_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N5_grammar_refined_examples.csv check complete\n"
     ]
    }
   ],
   "source": [
    "# check for missing columns\n",
    "\n",
    "all_rows = []\n",
    "header = None\n",
    "\n",
    "with open(output_csv, \"r\", encoding=\"utf-8-sig\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    header = next(reader)\n",
    "        \n",
    "    for line_num, row in enumerate(reader, start=2):\n",
    "        # Check if row is empty\n",
    "        if not row or all(cell.strip() == \"\" for cell in row):\n",
    "            print(f\"[INFO] {output_csv}, line {line_num}: Empty row skipped\")\n",
    "            continue\n",
    "        # Check if row has exactly 7 columns:\n",
    "        if len(row) != 7:\n",
    "            print(f\"[WARNING] {output_csv}, line {line_num}: Expected 6 columns, found {len(row)} => {row}\")\n",
    "        else:\n",
    "            all_rows.append(row)\n",
    "\n",
    "print(f\"{output_csv} check complete\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
